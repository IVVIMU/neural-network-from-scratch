{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2e03d4c6950>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "# context_length = 16\n",
    "max_seq_len = 16\n",
    "d_model = 64\n",
    "n_heads = 4\n",
    "n_layers = 4\n",
    "learning_rate = 1e-3\n",
    "dropout = 0.1\n",
    "max_iters = 5000\n",
    "eval_interval = 50\n",
    "eval_iters = 20\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "TORCH_SEED = 3047\n",
    "torch.manual_seed(TORCH_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('datasets/sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'\n",
    "    with open('datasets/sales_textbook.txt', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "\n",
    "with open('datasets/sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text size: 77919\n",
      "Vocabulary size: 77919\n",
      "The maximum value in the tokenized text is: 100069\n"
     ]
    }
   ],
   "source": [
    "# Using Tiktoken to tokenize the source text\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "tokenized_text = encoding.encode(text)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long)\n",
    "vocab_size = len(set(tokenized_text))\n",
    "max_token_value = max(tokenized_text)\n",
    "\n",
    "print(f'Tokenized text size: {len(tokenized_text)}')\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'The maximum value in the tokenized text is: {max_token_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 16]), torch.Size([4, 16]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and validation\n",
    "split_idx = int(len(tokenized_text) * 0.8)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]\n",
    "\n",
    "# training_batch\n",
    "idxs = torch.randint(low=0, high=len(train_data) - max_seq_len, size=(batch_size,))\n",
    "x_batch = torch.stack([train_data[idx:idx + max_seq_len] for idx in idxs])\n",
    "y_batch = torch.stack([train_data[idx + 1:idx + max_seq_len + 1] for idx in idxs])\n",
    "\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>433</td>\n",
       "      <td>374</td>\n",
       "      <td>16996</td>\n",
       "      <td>311</td>\n",
       "      <td>8881</td>\n",
       "      <td>323</td>\n",
       "      <td>63179</td>\n",
       "      <td>279</td>\n",
       "      <td>6130</td>\n",
       "      <td>596</td>\n",
       "      <td>14847</td>\n",
       "      <td>13</td>\n",
       "      <td>1115</td>\n",
       "      <td>15105</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1317</td>\n",
       "      <td>627</td>\n",
       "      <td>2520</td>\n",
       "      <td>54111</td>\n",
       "      <td>5552</td>\n",
       "      <td>311</td>\n",
       "      <td>5597</td>\n",
       "      <td>28846</td>\n",
       "      <td>11447</td>\n",
       "      <td>11</td>\n",
       "      <td>3085</td>\n",
       "      <td>19351</td>\n",
       "      <td>323</td>\n",
       "      <td>1862</td>\n",
       "      <td>311</td>\n",
       "      <td>21736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11411</td>\n",
       "      <td>311</td>\n",
       "      <td>9455</td>\n",
       "      <td>279</td>\n",
       "      <td>1888</td>\n",
       "      <td>6425</td>\n",
       "      <td>369</td>\n",
       "      <td>1124</td>\n",
       "      <td>627</td>\n",
       "      <td>644</td>\n",
       "      <td>17102</td>\n",
       "      <td>11</td>\n",
       "      <td>9204</td>\n",
       "      <td>22785</td>\n",
       "      <td>2802</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>12040</td>\n",
       "      <td>279</td>\n",
       "      <td>892</td>\n",
       "      <td>311</td>\n",
       "      <td>2610</td>\n",
       "      <td>1825</td>\n",
       "      <td>84175</td>\n",
       "      <td>4860</td>\n",
       "      <td>323</td>\n",
       "      <td>22815</td>\n",
       "      <td>9020</td>\n",
       "      <td>311</td>\n",
       "      <td>872</td>\n",
       "      <td>14847</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1     2      3     4     5     6      7      8     9      10  \\\n",
       "0     11    433   374  16996   311  8881   323  63179    279  6130    596   \n",
       "1   1317    627  2520  54111  5552   311  5597  28846  11447    11   3085   \n",
       "2  11411    311  9455    279  1888  6425   369   1124    627   644  17102   \n",
       "3     13  12040   279    892   311  2610  1825  84175   4860   323  22815   \n",
       "\n",
       "      11    12     13     14     15  \n",
       "0  14847    13   1115  15105    539  \n",
       "1  19351   323   1862    311  21736  \n",
       "2     11  9204  22785   2802    304  \n",
       "3   9020   311    872  14847     13  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\", it is crucial to reflect and summarize the customer's responses. This technique not\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(x_batch[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4084, -0.0766,  0.1495,  ...,  0.4334,  0.3934,  0.0186],\n",
       "        [-0.3088,  1.7746, -1.9879,  ..., -0.2933, -0.9630, -0.4039],\n",
       "        [-0.3746,  0.4040, -1.6022,  ...,  0.4541, -0.0680, -0.9949],\n",
       "        ...,\n",
       "        [-0.8532, -0.7116, -0.4817,  ...,  0.6795,  0.0603,  1.1497],\n",
       "        [ 0.6459, -0.1134, -0.3980,  ...,  0.5834, -1.3536,  1.3549],\n",
       "        [ 1.6187, -0.2309,  1.6308,  ...,  0.7032, -0.2993,  1.4346]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input embedding table\n",
    "input_embedding_lookup_table = nn.Embedding(max_token_value + 1, d_model)\n",
    "input_embedding_lookup_table.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_embedding = input_embedding_lookup_table(x_batch).to(device)\n",
    "y_batch_embedding = input_embedding_lookup_table(y_batch).to(device)\n",
    "\n",
    "x_batch_embedding, y_batch_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positional encoding\n",
    "from transformer_from_scratch.embedding.positional_encoding import PositionalEncoding\n",
    "\n",
    "positional_encoding = PositionalEncoding(d_model=d_model, max_seq_len=max_seq_len, device=device)\n",
    "positional_encoding = positional_encoding.positional_encoding.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "# [batch_size, seq_len, d_model]\n",
    "positional_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_embedding = x_batch_embedding + positional_encoding\n",
    "y_batch_embedding = x_batch_embedding + positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.128163</td>\n",
       "      <td>1.098318</td>\n",
       "      <td>0.061589</td>\n",
       "      <td>0.659486</td>\n",
       "      <td>-0.486816</td>\n",
       "      <td>-1.684022</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>-0.144989</td>\n",
       "      <td>1.098932</td>\n",
       "      <td>2.950274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586137</td>\n",
       "      <td>1.686508</td>\n",
       "      <td>-0.753595</td>\n",
       "      <td>1.446968</td>\n",
       "      <td>-1.097538</td>\n",
       "      <td>1.330085</td>\n",
       "      <td>-0.878640</td>\n",
       "      <td>1.390788</td>\n",
       "      <td>0.380007</td>\n",
       "      <td>2.132031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.224984</td>\n",
       "      <td>1.834972</td>\n",
       "      <td>0.391890</td>\n",
       "      <td>1.039342</td>\n",
       "      <td>1.002326</td>\n",
       "      <td>1.506255</td>\n",
       "      <td>0.933553</td>\n",
       "      <td>-0.084586</td>\n",
       "      <td>0.273862</td>\n",
       "      <td>1.943190</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.214233</td>\n",
       "      <td>0.296266</td>\n",
       "      <td>0.479791</td>\n",
       "      <td>1.206360</td>\n",
       "      <td>0.100527</td>\n",
       "      <td>-0.301546</td>\n",
       "      <td>-0.596328</td>\n",
       "      <td>0.335199</td>\n",
       "      <td>-0.328950</td>\n",
       "      <td>1.047948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.709460</td>\n",
       "      <td>2.405553</td>\n",
       "      <td>0.478345</td>\n",
       "      <td>-0.359229</td>\n",
       "      <td>0.712264</td>\n",
       "      <td>1.053070</td>\n",
       "      <td>2.090398</td>\n",
       "      <td>0.196823</td>\n",
       "      <td>1.711592</td>\n",
       "      <td>1.730036</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341380</td>\n",
       "      <td>-0.154286</td>\n",
       "      <td>0.437158</td>\n",
       "      <td>0.352002</td>\n",
       "      <td>-1.144311</td>\n",
       "      <td>1.890062</td>\n",
       "      <td>0.686984</td>\n",
       "      <td>2.137396</td>\n",
       "      <td>0.677471</td>\n",
       "      <td>0.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.687803</td>\n",
       "      <td>-0.035164</td>\n",
       "      <td>0.453855</td>\n",
       "      <td>-0.539957</td>\n",
       "      <td>-0.514900</td>\n",
       "      <td>0.320815</td>\n",
       "      <td>0.117010</td>\n",
       "      <td>0.744642</td>\n",
       "      <td>1.506247</td>\n",
       "      <td>0.805907</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003182</td>\n",
       "      <td>-1.810592</td>\n",
       "      <td>-0.917659</td>\n",
       "      <td>2.064042</td>\n",
       "      <td>-0.729338</td>\n",
       "      <td>0.875718</td>\n",
       "      <td>0.587507</td>\n",
       "      <td>2.125895</td>\n",
       "      <td>-1.236793</td>\n",
       "      <td>-1.225436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.466571</td>\n",
       "      <td>-1.589764</td>\n",
       "      <td>-0.452444</td>\n",
       "      <td>-2.848962</td>\n",
       "      <td>-0.391449</td>\n",
       "      <td>-0.294052</td>\n",
       "      <td>0.314704</td>\n",
       "      <td>-1.106485</td>\n",
       "      <td>1.848796</td>\n",
       "      <td>0.640990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633569</td>\n",
       "      <td>2.333714</td>\n",
       "      <td>-0.634152</td>\n",
       "      <td>1.278784</td>\n",
       "      <td>-0.910010</td>\n",
       "      <td>1.094407</td>\n",
       "      <td>-0.205325</td>\n",
       "      <td>1.954334</td>\n",
       "      <td>0.044860</td>\n",
       "      <td>-0.120603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.151568</td>\n",
       "      <td>0.799066</td>\n",
       "      <td>1.076717</td>\n",
       "      <td>-0.917921</td>\n",
       "      <td>1.902736</td>\n",
       "      <td>-1.722682</td>\n",
       "      <td>0.910654</td>\n",
       "      <td>0.126296</td>\n",
       "      <td>1.507143</td>\n",
       "      <td>-2.642344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432108</td>\n",
       "      <td>1.310794</td>\n",
       "      <td>2.867361</td>\n",
       "      <td>-0.445517</td>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.803569</td>\n",
       "      <td>1.808615</td>\n",
       "      <td>0.509389</td>\n",
       "      <td>-0.282991</td>\n",
       "      <td>1.647054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.606167</td>\n",
       "      <td>-1.072449</td>\n",
       "      <td>-0.482319</td>\n",
       "      <td>-0.340754</td>\n",
       "      <td>-0.254739</td>\n",
       "      <td>-1.708647</td>\n",
       "      <td>1.312923</td>\n",
       "      <td>-0.526044</td>\n",
       "      <td>2.225625</td>\n",
       "      <td>0.941511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430943</td>\n",
       "      <td>0.453285</td>\n",
       "      <td>-1.937428</td>\n",
       "      <td>1.839861</td>\n",
       "      <td>-0.682724</td>\n",
       "      <td>-0.290616</td>\n",
       "      <td>-0.686125</td>\n",
       "      <td>2.562037</td>\n",
       "      <td>-0.057366</td>\n",
       "      <td>0.903035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.670955</td>\n",
       "      <td>0.732331</td>\n",
       "      <td>-1.220412</td>\n",
       "      <td>0.670999</td>\n",
       "      <td>1.564215</td>\n",
       "      <td>-0.218517</td>\n",
       "      <td>1.145501</td>\n",
       "      <td>0.373214</td>\n",
       "      <td>0.285209</td>\n",
       "      <td>-1.377281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883945</td>\n",
       "      <td>1.907699</td>\n",
       "      <td>-1.401604</td>\n",
       "      <td>0.891313</td>\n",
       "      <td>-0.396377</td>\n",
       "      <td>0.891786</td>\n",
       "      <td>-2.270334</td>\n",
       "      <td>1.776717</td>\n",
       "      <td>-0.353932</td>\n",
       "      <td>1.630784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.333383</td>\n",
       "      <td>0.098351</td>\n",
       "      <td>-1.309119</td>\n",
       "      <td>2.373107</td>\n",
       "      <td>-1.221122</td>\n",
       "      <td>-0.648330</td>\n",
       "      <td>0.240119</td>\n",
       "      <td>-2.220782</td>\n",
       "      <td>1.847678</td>\n",
       "      <td>-1.169461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227376</td>\n",
       "      <td>2.118015</td>\n",
       "      <td>-1.067782</td>\n",
       "      <td>1.980372</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>0.736680</td>\n",
       "      <td>-0.656532</td>\n",
       "      <td>0.906004</td>\n",
       "      <td>-2.101119</td>\n",
       "      <td>1.252670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.595091</td>\n",
       "      <td>-1.312883</td>\n",
       "      <td>0.687742</td>\n",
       "      <td>1.216406</td>\n",
       "      <td>-1.838146</td>\n",
       "      <td>-1.903039</td>\n",
       "      <td>-1.301278</td>\n",
       "      <td>-2.901025</td>\n",
       "      <td>0.851294</td>\n",
       "      <td>-0.959089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>1.297597</td>\n",
       "      <td>-0.856803</td>\n",
       "      <td>-0.740361</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>2.505404</td>\n",
       "      <td>-1.421558</td>\n",
       "      <td>-0.047770</td>\n",
       "      <td>-1.499051</td>\n",
       "      <td>0.449086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.734778</td>\n",
       "      <td>-2.824995</td>\n",
       "      <td>2.153891</td>\n",
       "      <td>2.169474</td>\n",
       "      <td>-0.167033</td>\n",
       "      <td>0.830041</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.397144</td>\n",
       "      <td>-0.146173</td>\n",
       "      <td>-0.492405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368691</td>\n",
       "      <td>0.308713</td>\n",
       "      <td>0.273777</td>\n",
       "      <td>-1.503058</td>\n",
       "      <td>-0.300752</td>\n",
       "      <td>2.061598</td>\n",
       "      <td>0.209615</td>\n",
       "      <td>1.727619</td>\n",
       "      <td>0.615008</td>\n",
       "      <td>2.163859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.615894</td>\n",
       "      <td>-0.824093</td>\n",
       "      <td>1.485343</td>\n",
       "      <td>0.311340</td>\n",
       "      <td>0.594499</td>\n",
       "      <td>-0.039575</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>-1.100136</td>\n",
       "      <td>0.377795</td>\n",
       "      <td>0.209051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373898</td>\n",
       "      <td>2.564044</td>\n",
       "      <td>-0.445487</td>\n",
       "      <td>1.317466</td>\n",
       "      <td>0.105507</td>\n",
       "      <td>0.106875</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>1.522599</td>\n",
       "      <td>2.152684</td>\n",
       "      <td>3.401974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.262912</td>\n",
       "      <td>-0.435171</td>\n",
       "      <td>-0.285684</td>\n",
       "      <td>-0.661809</td>\n",
       "      <td>-0.471174</td>\n",
       "      <td>1.682409</td>\n",
       "      <td>-0.174943</td>\n",
       "      <td>-0.142992</td>\n",
       "      <td>-0.475054</td>\n",
       "      <td>-1.462281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125687</td>\n",
       "      <td>0.501790</td>\n",
       "      <td>1.666126</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>-1.440445</td>\n",
       "      <td>2.293291</td>\n",
       "      <td>-1.521079</td>\n",
       "      <td>0.504236</td>\n",
       "      <td>0.819281</td>\n",
       "      <td>2.345545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.473294</td>\n",
       "      <td>1.599390</td>\n",
       "      <td>-0.359904</td>\n",
       "      <td>-2.340457</td>\n",
       "      <td>2.398590</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>-0.753692</td>\n",
       "      <td>1.956174</td>\n",
       "      <td>0.830608</td>\n",
       "      <td>-1.867959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519137</td>\n",
       "      <td>1.501012</td>\n",
       "      <td>0.395126</td>\n",
       "      <td>0.872272</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>1.525707</td>\n",
       "      <td>-1.133440</td>\n",
       "      <td>0.728684</td>\n",
       "      <td>-0.337655</td>\n",
       "      <td>0.964587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.357302</td>\n",
       "      <td>-1.401009</td>\n",
       "      <td>0.130271</td>\n",
       "      <td>1.175943</td>\n",
       "      <td>0.927763</td>\n",
       "      <td>1.015033</td>\n",
       "      <td>0.197093</td>\n",
       "      <td>0.439691</td>\n",
       "      <td>-2.410270</td>\n",
       "      <td>1.114467</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.422478</td>\n",
       "      <td>2.795462</td>\n",
       "      <td>-0.034547</td>\n",
       "      <td>-0.228107</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.832030</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>1.520535</td>\n",
       "      <td>0.413111</td>\n",
       "      <td>0.317542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.303943</td>\n",
       "      <td>-1.024989</td>\n",
       "      <td>-1.474756</td>\n",
       "      <td>-0.266975</td>\n",
       "      <td>1.240080</td>\n",
       "      <td>-0.797127</td>\n",
       "      <td>-1.481465</td>\n",
       "      <td>1.282049</td>\n",
       "      <td>0.573856</td>\n",
       "      <td>0.175555</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.063048</td>\n",
       "      <td>0.733371</td>\n",
       "      <td>-0.105552</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>-1.856670</td>\n",
       "      <td>0.996517</td>\n",
       "      <td>-0.776179</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>1.330368</td>\n",
       "      <td>2.669598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -2.128163  1.098318  0.061589  0.659486 -0.486816 -1.684022  0.531371   \n",
       "1  -0.224984  1.834972  0.391890  1.039342  1.002326  1.506255  0.933553   \n",
       "2   0.709460  2.405553  0.478345 -0.359229  0.712264  1.053070  2.090398   \n",
       "3   1.687803 -0.035164  0.453855 -0.539957 -0.514900  0.320815  0.117010   \n",
       "4   0.466571 -1.589764 -0.452444 -2.848962 -0.391449 -0.294052  0.314704   \n",
       "5  -2.151568  0.799066  1.076717 -0.917921  1.902736 -1.722682  0.910654   \n",
       "6  -0.606167 -1.072449 -0.482319 -0.340754 -0.254739 -1.708647  1.312923   \n",
       "7   1.670955  0.732331 -1.220412  0.670999  1.564215 -0.218517  1.145501   \n",
       "8   1.333383  0.098351 -1.309119  2.373107 -1.221122 -0.648330  0.240119   \n",
       "9   0.595091 -1.312883  0.687742  1.216406 -1.838146 -1.903039 -1.301278   \n",
       "10  0.734778 -2.824995  2.153891  2.169474 -0.167033  0.830041  0.017782   \n",
       "11 -2.615894 -0.824093  1.485343  0.311340  0.594499 -0.039575 -0.000457   \n",
       "12 -1.262912 -0.435171 -0.285684 -0.661809 -0.471174  1.682409 -0.174943   \n",
       "13  1.473294  1.599390 -0.359904 -2.340457  2.398590  0.809159 -0.753692   \n",
       "14  0.357302 -1.401009  0.130271  1.175943  0.927763  1.015033  0.197093   \n",
       "15  2.303943 -1.024989 -1.474756 -0.266975  1.240080 -0.797127 -1.481465   \n",
       "\n",
       "          7         8         9   ...        54        55        56        57  \\\n",
       "0  -0.144989  1.098932  2.950274  ...  0.586137  1.686508 -0.753595  1.446968   \n",
       "1  -0.084586  0.273862  1.943190  ... -1.214233  0.296266  0.479791  1.206360   \n",
       "2   0.196823  1.711592  1.730036  ... -1.341380 -0.154286  0.437158  0.352002   \n",
       "3   0.744642  1.506247  0.805907  ...  1.003182 -1.810592 -0.917659  2.064042   \n",
       "4  -1.106485  1.848796  0.640990  ... -0.633569  2.333714 -0.634152  1.278784   \n",
       "5   0.126296  1.507143 -2.642344  ...  1.432108  1.310794  2.867361 -0.445517   \n",
       "6  -0.526044  2.225625  0.941511  ... -0.430943  0.453285 -1.937428  1.839861   \n",
       "7   0.373214  0.285209 -1.377281  ...  0.883945  1.907699 -1.401604  0.891313   \n",
       "8  -2.220782  1.847678 -1.169461  ... -0.227376  2.118015 -1.067782  1.980372   \n",
       "9  -2.901025  0.851294 -0.959089  ...  0.237300  1.297597 -0.856803 -0.740361   \n",
       "10  0.397144 -0.146173 -0.492405  ...  0.368691  0.308713  0.273777 -1.503058   \n",
       "11 -1.100136  0.377795  0.209051  ... -0.373898  2.564044 -0.445487  1.317466   \n",
       "12 -0.142992 -0.475054 -1.462281  ... -0.125687  0.501790  1.666126  0.333540   \n",
       "13  1.956174  0.830608 -1.867959  ...  0.519137  1.501012  0.395126  0.872272   \n",
       "14  0.439691 -2.410270  1.114467  ... -1.422478  2.795462 -0.034547 -0.228107   \n",
       "15  1.282049  0.573856  0.175555  ... -1.063048  0.733371 -0.105552  0.004757   \n",
       "\n",
       "          58        59        60        61        62        63  \n",
       "0  -1.097538  1.330085 -0.878640  1.390788  0.380007  2.132031  \n",
       "1   0.100527 -0.301546 -0.596328  0.335199 -0.328950  1.047948  \n",
       "2  -1.144311  1.890062  0.686984  2.137396  0.677471  0.322397  \n",
       "3  -0.729338  0.875718  0.587507  2.125895 -1.236793 -1.225436  \n",
       "4  -0.910010  1.094407 -0.205325  1.954334  0.044860 -0.120603  \n",
       "5   0.852830  0.803569  1.808615  0.509389 -0.282991  1.647054  \n",
       "6  -0.682724 -0.290616 -0.686125  2.562037 -0.057366  0.903035  \n",
       "7  -0.396377  0.891786 -2.270334  1.776717 -0.353932  1.630784  \n",
       "8   0.070198  0.736680 -0.656532  0.906004 -2.101119  1.252670  \n",
       "9   0.012208  2.505404 -1.421558 -0.047770 -1.499051  0.449086  \n",
       "10 -0.300752  2.061598  0.209615  1.727619  0.615008  2.163859  \n",
       "11  0.105507  0.106875  0.009023  1.522599  2.152684  3.401974  \n",
       "12 -1.440445  2.293291 -1.521079  0.504236  0.819281  2.345545  \n",
       "13  0.832359  1.525707 -1.133440  0.728684 -0.337655  0.964587  \n",
       "14  0.192980  0.832030 -0.766057  1.520535  0.413111  0.317542  \n",
       "15 -1.856670  0.996517 -0.776179  0.501220  1.330368  2.669598  \n",
       "\n",
       "[16 rows x 64 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_example = x_batch_embedding[0].detach().cpu().numpy()\n",
    "pd.DataFrame(x_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
